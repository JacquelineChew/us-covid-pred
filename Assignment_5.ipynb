{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacquelineChew/us-covid-pred/blob/main/Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IlwhV0z2nMr"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chprzdhe2nMw"
      },
      "source": [
        "# Assignment 5\n",
        "\n",
        "**DUE: Sunday March 14, 2021 11:59pm**\n",
        "\n",
        "Turn in the assignment via Canvas.\n",
        "\n",
        "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Runtime→→Restart runtime) and then run all cells (in the menubar, select Runtime→→Run All).\n",
        "\n",
        "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jeWubXE2nMx"
      },
      "source": [
        "NAME = \"Jacqueline\"\n",
        "STUDENT_ID = \"Chew\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-DjjESEyXnL"
      },
      "source": [
        "In this assignment you will use Recurrrent Neural Network architecture (and possible variations of it) to solve **one** of the following problems. For the problem you choose, you will have to follow the steps mentioned below.\n",
        "\n",
        "\n",
        "*   United States Corona Virus Cases Forecast\n",
        "> In this dataset you will use the data available at https://drive.google.com/file/d/1Y7PDnv5-HfmchT9FmFsGKsM3U6JMEABF to predict the number of positive COVID-19 cases in the USA. Note that the number of COVID-19 cases are cumulative.\n",
        "\n",
        "*   Reuters Topic Classification\n",
        "> We will use the [Reuters newswire](https://keras.io/api/datasets/reuters/) classification dataset, which has text paired with 46 topics as labels. You can see what these labels represent [here](https://martin-thoma.com/nlp-reuters/). You will analyze the text and classify the text into one of the 46 classes. Classes are the defined based on the following list (in the same order):\n",
        ">```\n",
        "['cocoa','grain','veg-oil','earn','acq','wheat','copper',\n",
        "'housing','money-supply','coffee','sugar','trade','reserves',\n",
        "'ship','cotton','carcass','crude','nat-gas','cpi','money-fx',\n",
        "'interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "'strategic-metal','livestock','retail','ipi','iron-steel',\n",
        "'rubber','heat','jobs','lei','bop','zinc','orange',\n",
        "'pet-chem','dlr','gas','silver','wpi','hog','lead']\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv1G7ixQvN8E"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import reuters # Import Reuters dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import textwrap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtiV5tgLLY5j"
      },
      "source": [
        "## Part 1: Reading the data (20 points)\n",
        "---\n",
        "\n",
        "In this part you need to:\n",
        "\n",
        "1) read in the data (for your task)\n",
        "> * For COVID-19 data you might find this lihnk useful: https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92. You need to use the public link to the dataset provided earlier so we can run your code on our end.\n",
        "> * For Reuters data, you can simply load it from Keras: https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters/load_data\n",
        "\n",
        "2) prepare and clean the data\n",
        "> * For COVID-19 dataset this means removing attributes you don't need (ex. Lat/Long features),  removing entries that are not relevant to your prediction task (ex. number of cases of other countries), and any other pre-processing you might find useful.\n",
        "Depending on your implementation you might find scaling also useful (Recall [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) from sklearn. **Hint**: You will need to call .transpose inorder to comply with required inputshape (n,1)). You might also find it useful to trim the data in the begining as reporting was not accurate on early days (>50,000 cases might be a reasonable cut-off).\n",
        "> * For Reuters news classification data, you may follow the RNN handout from the class exercise and prepare encoding and decoding functions and any other pre-processing you might find useful.\n",
        "\n",
        "3) Sample of the dataset\n",
        "> * For COVID-19 dataset print the head of your dataframe so we can see what data points and what features you will use for training.\n",
        "> * For Reuters news classification data, print an example of a news along with its class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnzsyAmwvImD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f159e8-4958-46d3-8c84-8ef37c88c19b"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load data\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "# Omit newswires longer than this many words\n",
        "max_sequence_len = 200\n",
        "# We do train_test_split later on so test_split is set as zero\n",
        "(X, y), (_, _) = reuters.load_data(maxlen=max_sequence_len, test_split=0)\n",
        "\n",
        "# Clean and pre-process the data\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "# Retrieves a dict mapping words to their index in the Reuters dataset.\n",
        "word_dict = reuters.get_word_index()\n",
        "\n",
        "for i in range(50):\n",
        "  for key, value in word_dict.items():\n",
        "    if value == i:\n",
        "        print('(', key, ',', value, ')', sep = '', end = ',')\n",
        "\n",
        "print(len(word_dict))\n",
        "\n",
        "word_dict = {k:(v+3) for k,v in word_dict.items()}\n",
        "word_dict[\"<PAD>\"] = 0\n",
        "word_dict[\"<START>\"] = 1\n",
        "word_dict[\"<UNK>\"] = 2\n",
        "word_dict[\"<UNUSED>\"] = 3\n",
        "\n",
        "vocab_size = len(word_dict.keys())\n",
        "print('Number of words in vocabulary: ', vocab_size)\n",
        "\n",
        "for i in range(50):\n",
        "  for key, value in word_dict.items():\n",
        "    if value == i:\n",
        "        print('(', key, ',', value, ')', sep = '', end = ',')\n",
        "\n",
        "# Needed to decode training data into readable text\n",
        "inverse_word_dict = {value:key for key,value in word_dict.items()}\n",
        "\n",
        "# Print sample data\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "print(\"\\n\")\n",
        "for i in range(len(X)):\n",
        "  X[i] = np.asarray(X[i])\n",
        "# Print out the last newswire in the dataset\n",
        "print(X[-1])\n",
        "# Make sure that all newswires have the same size array\n",
        "X = pad_sequences(X, maxlen=max_sequence_len)\n",
        "print(X[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(the,1),(of,2),(to,3),(in,4),(said,5),(and,6),(a,7),(mln,8),(3,9),(for,10),(vs,11),(dlrs,12),(it,13),(reuter,14),(000,15),(1,16),(pct,17),(on,18),(from,19),(is,20),(that,21),(its,22),(cts,23),(by,24),(at,25),(year,26),(be,27),(with,28),(2,29),(will,30),(was,31),(billion,32),(he,33),(u,34),(s,35),(net,36),(has,37),(would,38),(an,39),(as,40),(5,41),(not,42),(loss,43),(4,44),(1986,45),(company,46),(which,47),(but,48),(this,49),30979\n",
            "Number of words in vocabulary:  30983\n",
            "(<PAD>,0),(<START>,1),(<UNK>,2),(<UNUSED>,3),(the,4),(of,5),(to,6),(in,7),(said,8),(and,9),(a,10),(mln,11),(3,12),(for,13),(vs,14),(dlrs,15),(it,16),(reuter,17),(000,18),(1,19),(pct,20),(on,21),(from,22),(is,23),(that,24),(its,25),(cts,26),(by,27),(at,28),(year,29),(be,30),(with,31),(2,32),(will,33),(was,34),(billion,35),(he,36),(u,37),(s,38),(net,39),(has,40),(would,41),(an,42),(as,43),(5,44),(not,45),(loss,46),(4,47),(1986,48),(company,49),\n",
            "\n",
            "[    1  5586 15148    71     8    23   166   344    10    78    13    68\n",
            "    80   467   606     6   261     5   146    93   124     4   166    75\n",
            "  3603 14296  5907   265  8692  1251 14144   297  1127   195     9   621\n",
            "   575  1080  5907     7   378   104   421   648    20     5     4    49\n",
            " 14144     8  1708    28     4   303   163   524    10  1220     6   455\n",
            "     4   326   685     6 15081   422    71   142    73   863    62    75\n",
            "  3603     6     4   326   166 14144    34  1652  3603     6     4   166\n",
            "     4    49     8    17    12]\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     1  5586 15148    71     8    23   166   344    10\n",
            "    78    13    68    80   467   606     6   261     5   146    93   124\n",
            "     4   166    75  3603 14296  5907   265  8692  1251 14144   297  1127\n",
            "   195     9   621   575  1080  5907     7   378   104   421   648    20\n",
            "     5     4    49 14144     8  1708    28     4   303   163   524    10\n",
            "  1220     6   455     4   326   685     6 15081   422    71   142    73\n",
            "   863    62    75  3603     6     4   326   166 14144    34  1652  3603\n",
            "     6     4   166     4    49     8    17    12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3TG8lGmr3ZW"
      },
      "source": [
        "# Functions are modeled after Lecture 18 class exercise\n",
        "def encode_news(newswire, word_dict, maxlen):\n",
        "  encoded_news = []\n",
        "  for raw_word in newswire.split(' '):\n",
        "    word = raw_word.strip().strip(string.punctuation).lower()\n",
        "    if word is '' or word is '\\n':\n",
        "      continue\n",
        "    try:\n",
        "      encoded_news.append(word_dict[word])\n",
        "    except KeyError as e:\n",
        "      # raise KeyError(f'{e} not in word dictionary, newswire not encoded.')\n",
        "      continue\n",
        "  return pad_sequences(np.array(encoded_news).reshape(1,-1), maxlen=maxlen)\n",
        "\n",
        "def decode_news(encoded_news, inverse_word_dict):\n",
        "  sentence = []\n",
        "  for encoded_word in encoded_news:\n",
        "    if encoded_word == 0:\n",
        "      continue\n",
        "    sentence.append(inverse_word_dict[encoded_word])\n",
        "  w = textwrap.TextWrapper(width=120,break_long_words=False,replace_whitespace=False)\n",
        "  return '\\n'.join(w.wrap(' '.join(sentence)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzVN-CBqsAVL",
        "outputId": "1d58aa78-8b27-4151-c485-a3784223891f"
      },
      "source": [
        "# Print an example of a news along with its class label\n",
        "print(decode_news(X[-1], inverse_word_dict), end='\\n\\n')\n",
        "\n",
        "print('Class: ', y[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> inland vacuum inc said is board proposed a two for one stock split payable to shareholders of record april 30\n",
            "the board also elected phillip frost chairman succeeding john durkin who remains president and chief executive officer\n",
            "frost in early february bought 49 pct of the company durkin said stockholders at the annual meeting approved a measure\n",
            "to change the company's name to ivaco industries inc five new directors were also elected to the company's board durkin\n",
            "was re elected to the board the company said reuter 3\n",
            "\n",
            "Class:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7AZBFBPSLtH"
      },
      "source": [
        "4) An additional step for COVID-19 data\n",
        ">You need to modify your dataset so you determine how many days back the model will look to generate a new prediction. Begin with time_step=2. In the training phase you can choose different time-steps (and modify the architecture accordingly)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4fI2NvCJXUb"
      },
      "source": [
        "# You may use the following function to process your dataset further.\n",
        "# Generate a dataset where X[n] contains the readings for the 'time_step' previous days\n",
        "# and y contains the reading for today.\n",
        "# def create_dataset(dataset, time_steps=1):\n",
        "# \tdataX, dataY = [], []\n",
        "# \tfor i in range(len(dataset)-time_steps-1):\n",
        "# \t\ta = dataset[i:(i+time_steps), 0]\n",
        "# \t\tdataX.append(a)\n",
        "# \t\tdataY.append(dataset[i + time_steps, 0])\n",
        "# \treturn np.array(dataX), np.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zteRBuvvOW4m"
      },
      "source": [
        "# Choose the number of time steps that the model \"looks back\"\n",
        "# time_steps = 2\n",
        "# dataX, dataY = create_dataset(X, time_steps=time_steps)\n",
        "# dataX[:5], dataY[:5]\n",
        "\n",
        "# Produce your dataset based on the number of days the model could look back\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "# Print head of the data\n",
        "\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyIDtW-U7RJn"
      },
      "source": [
        "## Part 2: Data Partitioning (5 points)\n",
        "---\n",
        "Split data into train and test sets. Please use 80\\% for training and 20\\% for testing. Note:\n",
        "> * for COVID-19 dataset you need to split the data in time (the begining 80\\% of the days from start date will be the training data and the remaining 20\\% will be test data).\n",
        "> * for Reuters dataset, we want to have the same distribution of labels in the training and test set, so you can simply use stratified train-test split of Keras. See here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM3fOjNG0ybv"
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratify ensures that proportion of values in sample will be the same as\n",
        "# the proportion of values provided to the parameter (ex. y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjoKH7hGXY6r"
      },
      "source": [
        "For COVID-19 dataset, you need to reshape the partitions for the model to be able to process them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD7omR6XXjgK"
      },
      "source": [
        "# Reshape input to be [samples, time steps, features]. For example:\n",
        "# X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "# X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp8HvntUTzwW"
      },
      "source": [
        "## Part 3: Simple RNN Model (25 points)\n",
        "---\n",
        "\n",
        "In this part you will create a model using an RNN layer (LSTM or GRU, unidirectional or bidirectional) and train it on your training data. You will also plot training and validation loss and your metric (accuracies (for Reuters data) and mean squared error (for COVID-19 data))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L2aeGG9KS7w"
      },
      "source": [
        "Compile your model and display the summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09k-v7zVzUXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314e7b2e-b6fb-4ad7-c103-cb29bbba045d"
      },
      "source": [
        "# Build your model\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, Input, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_layer = Input(shape=(max_sequence_len))\n",
        "x = Embedding(vocab_size, 256, mask_zero=True)(input_layer)\n",
        "\n",
        "x = LSTM(256)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(46, activation='softmax')(x)\n",
        "reuters_model = Model(input_layer, x)\n",
        "\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(2e-4)\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "reuters_model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=metrics)\n",
        "\n",
        "reuters_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 200, 256)          7931648   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 46)                1518      \n",
            "=================================================================\n",
            "Total params: 8,477,006\n",
            "Trainable params: 8,477,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mthwaqCrzvM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372320b6-d3e7-44d5-dc2a-6dc608060594"
      },
      "source": [
        "batchsize = 1024\n",
        "epochs =  100\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  # Fit model\n",
        "  history = reuters_model.fit(X_train, y_train, batch_size=batchsize, epochs=epochs, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 9s 915ms/step - loss: 3.8285 - accuracy: 0.0217 - val_loss: 3.8236 - val_accuracy: 0.1278\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 4s 637ms/step - loss: 3.8214 - accuracy: 0.1636 - val_loss: 3.8133 - val_accuracy: 0.1709\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 4s 645ms/step - loss: 3.8094 - accuracy: 0.2033 - val_loss: 3.7950 - val_accuracy: 0.2429\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 4s 652ms/step - loss: 3.7870 - accuracy: 0.2751 - val_loss: 3.7527 - val_accuracy: 0.3347\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 4s 673ms/step - loss: 3.7219 - accuracy: 0.3832 - val_loss: 3.5647 - val_accuracy: 0.4089\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 3.5292 - accuracy: 0.4114 - val_loss: 3.3777 - val_accuracy: 0.2366\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 4s 637ms/step - loss: 3.3176 - accuracy: 0.3359 - val_loss: 3.0797 - val_accuracy: 0.4004\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 4s 644ms/step - loss: 3.0217 - accuracy: 0.4048 - val_loss: 2.8472 - val_accuracy: 0.5162\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 4s 644ms/step - loss: 2.7998 - accuracy: 0.5278 - val_loss: 2.7390 - val_accuracy: 0.5939\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 4s 655ms/step - loss: 2.6672 - accuracy: 0.5729 - val_loss: 2.6133 - val_accuracy: 0.6102\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 4s 646ms/step - loss: 2.5275 - accuracy: 0.5850 - val_loss: 2.5076 - val_accuracy: 0.6081\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 4s 634ms/step - loss: 2.4822 - accuracy: 0.5789 - val_loss: 2.4474 - val_accuracy: 0.6059\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 4s 645ms/step - loss: 2.4616 - accuracy: 0.5822 - val_loss: 2.3543 - val_accuracy: 0.6123\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 2.3735 - accuracy: 0.5864 - val_loss: 2.3484 - val_accuracy: 0.6095\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 4s 646ms/step - loss: 2.3496 - accuracy: 0.5887 - val_loss: 2.3596 - val_accuracy: 0.6059\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 2.3103 - accuracy: 0.5891 - val_loss: 2.1926 - val_accuracy: 0.6088\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 2.1989 - accuracy: 0.5793 - val_loss: 2.1263 - val_accuracy: 0.5975\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 2.1841 - accuracy: 0.5700 - val_loss: 2.0938 - val_accuracy: 0.5890\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 4s 634ms/step - loss: 2.1490 - accuracy: 0.5634 - val_loss: 2.0380 - val_accuracy: 0.5904\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 4s 625ms/step - loss: 2.0952 - accuracy: 0.5699 - val_loss: 1.9907 - val_accuracy: 0.5946\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 4s 643ms/step - loss: 2.0499 - accuracy: 0.5702 - val_loss: 1.9472 - val_accuracy: 0.5989\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 4s 648ms/step - loss: 2.0338 - accuracy: 0.5710 - val_loss: 1.9301 - val_accuracy: 0.5989\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 4s 635ms/step - loss: 2.0322 - accuracy: 0.5684 - val_loss: 1.9182 - val_accuracy: 0.5982\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 4s 643ms/step - loss: 1.9753 - accuracy: 0.5772 - val_loss: 1.9030 - val_accuracy: 0.5975\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 1.9824 - accuracy: 0.5751 - val_loss: 1.8945 - val_accuracy: 0.5968\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 4s 630ms/step - loss: 1.9333 - accuracy: 0.5789 - val_loss: 1.8809 - val_accuracy: 0.5968\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 4s 627ms/step - loss: 1.9406 - accuracy: 0.5761 - val_loss: 1.8684 - val_accuracy: 0.5968\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 4s 636ms/step - loss: 1.9318 - accuracy: 0.5767 - val_loss: 1.8571 - val_accuracy: 0.5968\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 4s 636ms/step - loss: 1.9084 - accuracy: 0.5752 - val_loss: 1.8459 - val_accuracy: 0.5968\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 4s 629ms/step - loss: 1.8946 - accuracy: 0.5781 - val_loss: 1.8333 - val_accuracy: 0.5975\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.8871 - accuracy: 0.5793 - val_loss: 1.8288 - val_accuracy: 0.5960\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 4s 636ms/step - loss: 1.8836 - accuracy: 0.5741 - val_loss: 1.8215 - val_accuracy: 0.5968\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 4s 642ms/step - loss: 1.8918 - accuracy: 0.5700 - val_loss: 1.8136 - val_accuracy: 0.5968\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 4s 648ms/step - loss: 1.8733 - accuracy: 0.5757 - val_loss: 1.8061 - val_accuracy: 0.5960\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 4s 628ms/step - loss: 1.8566 - accuracy: 0.5757 - val_loss: 1.8020 - val_accuracy: 0.5960\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 4s 625ms/step - loss: 1.8522 - accuracy: 0.5790 - val_loss: 1.7955 - val_accuracy: 0.5968\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 4s 637ms/step - loss: 1.8890 - accuracy: 0.5686 - val_loss: 1.7942 - val_accuracy: 0.5953\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 4s 649ms/step - loss: 1.8479 - accuracy: 0.5772 - val_loss: 1.7902 - val_accuracy: 0.5960\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 4s 660ms/step - loss: 1.8575 - accuracy: 0.5714 - val_loss: 1.7867 - val_accuracy: 0.5960\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 1.8661 - accuracy: 0.5700 - val_loss: 1.7730 - val_accuracy: 0.5968\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 4s 643ms/step - loss: 1.8322 - accuracy: 0.5782 - val_loss: 1.7835 - val_accuracy: 0.5897\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 4s 631ms/step - loss: 1.7989 - accuracy: 0.5808 - val_loss: 1.7744 - val_accuracy: 0.5904\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 4s 640ms/step - loss: 1.8097 - accuracy: 0.5740 - val_loss: 1.7630 - val_accuracy: 0.5939\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 4s 642ms/step - loss: 1.8500 - accuracy: 0.5658 - val_loss: 1.7577 - val_accuracy: 0.5939\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 4s 646ms/step - loss: 1.8108 - accuracy: 0.5733 - val_loss: 1.7554 - val_accuracy: 0.5939\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 4s 641ms/step - loss: 1.7963 - accuracy: 0.5723 - val_loss: 1.7552 - val_accuracy: 0.5939\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.8095 - accuracy: 0.5716 - val_loss: 1.7489 - val_accuracy: 0.5939\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 4s 628ms/step - loss: 1.8198 - accuracy: 0.5650 - val_loss: 1.7426 - val_accuracy: 0.5932\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 4s 643ms/step - loss: 1.7586 - accuracy: 0.5791 - val_loss: 1.8130 - val_accuracy: 0.6010\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 4s 640ms/step - loss: 1.8063 - accuracy: 0.5705 - val_loss: 1.7497 - val_accuracy: 0.5918\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 4s 650ms/step - loss: 1.7972 - accuracy: 0.5680 - val_loss: 1.7476 - val_accuracy: 0.5883\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.8095 - accuracy: 0.5655 - val_loss: 1.7469 - val_accuracy: 0.5869\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 4s 646ms/step - loss: 1.8235 - accuracy: 0.5558 - val_loss: 1.7406 - val_accuracy: 0.5869\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 4s 644ms/step - loss: 1.7907 - accuracy: 0.5622 - val_loss: 1.7210 - val_accuracy: 0.5876\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 4s 642ms/step - loss: 1.7752 - accuracy: 0.5605 - val_loss: 1.6620 - val_accuracy: 0.5890\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 4s 641ms/step - loss: 1.6980 - accuracy: 0.5713 - val_loss: 1.6587 - val_accuracy: 0.5890\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 4s 658ms/step - loss: 1.6654 - accuracy: 0.5657 - val_loss: 1.6319 - val_accuracy: 0.5883\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 4s 645ms/step - loss: 1.6360 - accuracy: 0.5670 - val_loss: 1.5729 - val_accuracy: 0.5883\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 4s 646ms/step - loss: 1.5968 - accuracy: 0.5615 - val_loss: 1.5744 - val_accuracy: 0.5897\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 4s 644ms/step - loss: 1.5522 - accuracy: 0.5730 - val_loss: 1.5933 - val_accuracy: 0.5932\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 4s 647ms/step - loss: 1.5871 - accuracy: 0.5742 - val_loss: 1.7779 - val_accuracy: 0.5890\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.6695 - accuracy: 0.5795 - val_loss: 1.5750 - val_accuracy: 0.6109\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 4s 628ms/step - loss: 1.5638 - accuracy: 0.5892 - val_loss: 1.6529 - val_accuracy: 0.5742\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 4s 631ms/step - loss: 1.5908 - accuracy: 0.5940 - val_loss: 1.6604 - val_accuracy: 0.5946\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 1.5782 - accuracy: 0.5809 - val_loss: 1.5961 - val_accuracy: 0.5989\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 4s 647ms/step - loss: 1.5395 - accuracy: 0.6080 - val_loss: 1.5485 - val_accuracy: 0.6116\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 4s 645ms/step - loss: 1.4925 - accuracy: 0.5989 - val_loss: 1.5622 - val_accuracy: 0.6073\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.5145 - accuracy: 0.5938 - val_loss: 1.5470 - val_accuracy: 0.6130\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 4s 637ms/step - loss: 1.5170 - accuracy: 0.5888 - val_loss: 1.5237 - val_accuracy: 0.6116\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 1.5056 - accuracy: 0.6095 - val_loss: 1.5259 - val_accuracy: 0.6179\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 1.4750 - accuracy: 0.6034 - val_loss: 1.5395 - val_accuracy: 0.6179\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.4644 - accuracy: 0.6018 - val_loss: 1.5194 - val_accuracy: 0.6186\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 4s 631ms/step - loss: 1.4266 - accuracy: 0.6192 - val_loss: 1.5268 - val_accuracy: 0.6003\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 4s 622ms/step - loss: 1.4243 - accuracy: 0.6157 - val_loss: 1.5185 - val_accuracy: 0.6158\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 4s 676ms/step - loss: 1.4141 - accuracy: 0.6182 - val_loss: 1.5266 - val_accuracy: 0.6165\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 4s 627ms/step - loss: 1.4262 - accuracy: 0.6112 - val_loss: 1.5602 - val_accuracy: 0.6158\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 4s 645ms/step - loss: 1.4117 - accuracy: 0.6100 - val_loss: 1.5166 - val_accuracy: 0.6081\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 4s 641ms/step - loss: 1.3820 - accuracy: 0.6189 - val_loss: 1.5248 - val_accuracy: 0.6088\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 4s 640ms/step - loss: 1.3730 - accuracy: 0.6116 - val_loss: 1.5551 - val_accuracy: 0.6144\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 1.3623 - accuracy: 0.6155 - val_loss: 1.5333 - val_accuracy: 0.6123\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 4s 635ms/step - loss: 1.3505 - accuracy: 0.6189 - val_loss: 1.5304 - val_accuracy: 0.6102\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 4s 650ms/step - loss: 1.3359 - accuracy: 0.6203 - val_loss: 1.5376 - val_accuracy: 0.6123\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 4s 633ms/step - loss: 1.3208 - accuracy: 0.6203 - val_loss: 1.5340 - val_accuracy: 0.6116\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 1.2865 - accuracy: 0.6261 - val_loss: 1.5395 - val_accuracy: 0.6073\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.2705 - accuracy: 0.6294 - val_loss: 1.5435 - val_accuracy: 0.6038\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 4s 640ms/step - loss: 1.2870 - accuracy: 0.6239 - val_loss: 1.5510 - val_accuracy: 0.6073\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 4s 643ms/step - loss: 1.2622 - accuracy: 0.6257 - val_loss: 1.5602 - val_accuracy: 0.6109\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 4s 642ms/step - loss: 1.2675 - accuracy: 0.6214 - val_loss: 1.5832 - val_accuracy: 0.6003\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 4s 627ms/step - loss: 1.3120 - accuracy: 0.6081 - val_loss: 1.6611 - val_accuracy: 0.5636\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 4s 623ms/step - loss: 1.3325 - accuracy: 0.6043 - val_loss: 1.6216 - val_accuracy: 0.5847\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 4s 638ms/step - loss: 1.2884 - accuracy: 0.6184 - val_loss: 1.7320 - val_accuracy: 0.5452\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 4s 619ms/step - loss: 1.3215 - accuracy: 0.6113 - val_loss: 1.6509 - val_accuracy: 0.5685\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 4s 640ms/step - loss: 1.2948 - accuracy: 0.6104 - val_loss: 1.6122 - val_accuracy: 0.6130\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 4s 649ms/step - loss: 1.2317 - accuracy: 0.6245 - val_loss: 1.6067 - val_accuracy: 0.6059\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 4s 632ms/step - loss: 1.2453 - accuracy: 0.6210 - val_loss: 1.6054 - val_accuracy: 0.5939\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 4s 631ms/step - loss: 1.2134 - accuracy: 0.6222 - val_loss: 1.6225 - val_accuracy: 0.5890\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 4s 642ms/step - loss: 1.2042 - accuracy: 0.6242 - val_loss: 1.6384 - val_accuracy: 0.6017\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 4s 625ms/step - loss: 1.2059 - accuracy: 0.6236 - val_loss: 1.6588 - val_accuracy: 0.6010\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 4s 631ms/step - loss: 1.1697 - accuracy: 0.6337 - val_loss: 1.6564 - val_accuracy: 0.5996\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 4s 621ms/step - loss: 1.1715 - accuracy: 0.6274 - val_loss: 1.6658 - val_accuracy: 0.6010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBzaRs9hrQsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "edc5f3d6-bd72-485c-cc45-42c4f9d1b215"
      },
      "source": [
        "# Plot the Model loss\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ONEJCKBa384"
      },
      "source": [
        "## Part 4: More Advanced RNN Model (30 points)\n",
        "---\n",
        "In this part you will create an RNN model with the number of layers and architerure you prefer. Train it on your training data. You will also plot training and validation loss and your metric (accuracies (for Reuters data) and mean squared error (for COVID-19 data)). In this part, you can try different models and use different hyper-parameters and report only the best one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToO-cZbKa386"
      },
      "source": [
        "Compile your model and display the summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOo5_Rp6a386",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a88371e-487a-4346-8056-34006049c6ff"
      },
      "source": [
        "# Build your model\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "import tensorflow as tf\n",
        "input_layer = Input(shape=(max_sequence_len))\n",
        "x = Embedding(vocab_size, 256, mask_zero=True)(input_layer)\n",
        "\n",
        "x = LSTM(256)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "# x = Dropout(0.4)(x)\n",
        "# x = Dense(32, activation='relu')(x)\n",
        "# x = Dropout(0.8)(x)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "x = Dense(46, activation='softmax')(x)  # 46 classes\n",
        "model = Model(input_layer, x)\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(0.0003)\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=metrics)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 200, 256)          7931648   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 46)                2990      \n",
            "=================================================================\n",
            "Total params: 8,476,398\n",
            "Trainable params: 8,476,398\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80rNRrDva387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f574c0-949f-4f2e-8bd5-dd78b576eb81"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "batchsize = 1024\n",
        "epochs =  100\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  # Fit model\n",
        "  history = model.fit(X_train,\n",
        "                      y_train,\n",
        "                      batch_size=batchsize,\n",
        "                      epochs=epochs,\n",
        "                      validation_split=0.2,\n",
        "                      shuffle=True,\n",
        "                      callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 9s 863ms/step - loss: 3.8188 - accuracy: 0.1445 - val_loss: 3.7818 - val_accuracy: 0.2733\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 3.7664 - accuracy: 0.2572 - val_loss: 3.6791 - val_accuracy: 0.2874\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 4s 662ms/step - loss: 3.5899 - accuracy: 0.2422 - val_loss: 2.8554 - val_accuracy: 0.2472\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 2.8203 - accuracy: 0.2599 - val_loss: 2.5457 - val_accuracy: 0.4103\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 4s 670ms/step - loss: 2.6020 - accuracy: 0.4180 - val_loss: 2.4134 - val_accuracy: 0.4103\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 4s 652ms/step - loss: 2.4397 - accuracy: 0.4204 - val_loss: 2.3468 - val_accuracy: 0.4103\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 4s 672ms/step - loss: 2.4058 - accuracy: 0.4085 - val_loss: 2.3059 - val_accuracy: 0.4103\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 4s 647ms/step - loss: 2.3586 - accuracy: 0.4124 - val_loss: 2.2794 - val_accuracy: 0.4103\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 4s 655ms/step - loss: 2.3256 - accuracy: 0.4124 - val_loss: 2.2556 - val_accuracy: 0.4103\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 4s 651ms/step - loss: 2.3323 - accuracy: 0.4070 - val_loss: 2.2377 - val_accuracy: 0.4103\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 4s 660ms/step - loss: 2.2949 - accuracy: 0.4103 - val_loss: 2.2181 - val_accuracy: 0.4103\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 4s 655ms/step - loss: 2.2631 - accuracy: 0.4132 - val_loss: 2.1904 - val_accuracy: 0.4103\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 4s 657ms/step - loss: 2.2413 - accuracy: 0.4112 - val_loss: 2.1454 - val_accuracy: 0.4103\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 4s 650ms/step - loss: 2.1965 - accuracy: 0.4179 - val_loss: 2.0945 - val_accuracy: 0.4103\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 2.1406 - accuracy: 0.4130 - val_loss: 2.0622 - val_accuracy: 0.4103\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 2.0825 - accuracy: 0.4719 - val_loss: 1.9233 - val_accuracy: 0.4258\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 4s 660ms/step - loss: 1.9603 - accuracy: 0.4939 - val_loss: 1.8559 - val_accuracy: 0.5918\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 4s 652ms/step - loss: 1.9175 - accuracy: 0.5688 - val_loss: 1.8852 - val_accuracy: 0.5494\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 4s 651ms/step - loss: 2.0004 - accuracy: 0.4986 - val_loss: 1.8277 - val_accuracy: 0.4477\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 4s 652ms/step - loss: 1.8609 - accuracy: 0.5329 - val_loss: 1.7414 - val_accuracy: 0.6081\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 4s 651ms/step - loss: 1.8214 - accuracy: 0.5810 - val_loss: 1.7443 - val_accuracy: 0.5148\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 4s 661ms/step - loss: 1.7886 - accuracy: 0.5460 - val_loss: 1.6885 - val_accuracy: 0.6229\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 4s 661ms/step - loss: 1.7500 - accuracy: 0.5997 - val_loss: 1.7283 - val_accuracy: 0.6179\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 4s 654ms/step - loss: 1.7604 - accuracy: 0.6024 - val_loss: 1.7359 - val_accuracy: 0.6003\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 4s 649ms/step - loss: 1.7855 - accuracy: 0.5871 - val_loss: 1.6823 - val_accuracy: 0.6208\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 4s 642ms/step - loss: 1.7174 - accuracy: 0.6137 - val_loss: 1.6709 - val_accuracy: 0.6222\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 4s 647ms/step - loss: 1.6981 - accuracy: 0.6137 - val_loss: 1.6494 - val_accuracy: 0.6236\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 4s 648ms/step - loss: 1.6942 - accuracy: 0.6124 - val_loss: 1.6529 - val_accuracy: 0.5911\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 4s 673ms/step - loss: 1.7002 - accuracy: 0.5985 - val_loss: 1.6552 - val_accuracy: 0.6250\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 4s 657ms/step - loss: 1.6990 - accuracy: 0.6056 - val_loss: 1.7497 - val_accuracy: 0.5982\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 4s 672ms/step - loss: 1.7731 - accuracy: 0.5880 - val_loss: 1.6516 - val_accuracy: 0.6236\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 4s 662ms/step - loss: 1.7079 - accuracy: 0.5951 - val_loss: 1.6355 - val_accuracy: 0.6201\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 4s 665ms/step - loss: 1.6799 - accuracy: 0.6074 - val_loss: 1.6252 - val_accuracy: 0.6250\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 1.6553 - accuracy: 0.6182 - val_loss: 1.6193 - val_accuracy: 0.6186\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 4s 658ms/step - loss: 1.6531 - accuracy: 0.6147 - val_loss: 1.6418 - val_accuracy: 0.6130\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 4s 661ms/step - loss: 1.6464 - accuracy: 0.6086 - val_loss: 1.6184 - val_accuracy: 0.6158\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 4s 647ms/step - loss: 1.6176 - accuracy: 0.6072 - val_loss: 1.5740 - val_accuracy: 0.6116\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 1.5430 - accuracy: 0.6228 - val_loss: 1.5514 - val_accuracy: 0.6208\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 4s 668ms/step - loss: 1.5689 - accuracy: 0.6116 - val_loss: 1.5411 - val_accuracy: 0.6194\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 4s 657ms/step - loss: 1.5029 - accuracy: 0.6206 - val_loss: 1.5836 - val_accuracy: 0.6370\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 1.5234 - accuracy: 0.6213 - val_loss: 1.5025 - val_accuracy: 0.6222\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 4s 650ms/step - loss: 1.4517 - accuracy: 0.6474 - val_loss: 1.4815 - val_accuracy: 0.6462\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 1.4469 - accuracy: 0.6583 - val_loss: 1.4676 - val_accuracy: 0.6596\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 4s 669ms/step - loss: 1.4120 - accuracy: 0.6614 - val_loss: 1.4574 - val_accuracy: 0.6518\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 1.4336 - accuracy: 0.6481 - val_loss: 1.4438 - val_accuracy: 0.6427\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 4s 639ms/step - loss: 1.3801 - accuracy: 0.6557 - val_loss: 1.4344 - val_accuracy: 0.6624\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 4s 646ms/step - loss: 1.3894 - accuracy: 0.6612 - val_loss: 1.4474 - val_accuracy: 0.6631\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 4s 658ms/step - loss: 1.3513 - accuracy: 0.6681 - val_loss: 1.4522 - val_accuracy: 0.6568\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 4s 663ms/step - loss: 1.3304 - accuracy: 0.6726 - val_loss: 1.4389 - val_accuracy: 0.6653\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 4s 658ms/step - loss: 1.3379 - accuracy: 0.6780 - val_loss: 1.4806 - val_accuracy: 0.6547\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 4s 668ms/step - loss: 1.3661 - accuracy: 0.6703 - val_loss: 1.4750 - val_accuracy: 0.6356\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 1.3560 - accuracy: 0.6714 - val_loss: 1.4719 - val_accuracy: 0.6638\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 4s 666ms/step - loss: 1.3698 - accuracy: 0.6701 - val_loss: 1.4997 - val_accuracy: 0.6469\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 4s 679ms/step - loss: 1.3221 - accuracy: 0.6738 - val_loss: 1.4448 - val_accuracy: 0.6582\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 4s 678ms/step - loss: 1.3669 - accuracy: 0.6572 - val_loss: 1.4944 - val_accuracy: 0.6532\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 4s 677ms/step - loss: 1.3658 - accuracy: 0.6588 - val_loss: 1.5302 - val_accuracy: 0.6483\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 4s 664ms/step - loss: 1.4296 - accuracy: 0.6362 - val_loss: 1.4938 - val_accuracy: 0.6278\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 4s 663ms/step - loss: 1.4131 - accuracy: 0.6259 - val_loss: 1.4941 - val_accuracy: 0.6370\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 4s 663ms/step - loss: 1.4155 - accuracy: 0.6385 - val_loss: 1.4607 - val_accuracy: 0.6448\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 4s 670ms/step - loss: 1.3707 - accuracy: 0.6376 - val_loss: 1.4686 - val_accuracy: 0.6483\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 4s 675ms/step - loss: 1.3533 - accuracy: 0.6437 - val_loss: 1.4439 - val_accuracy: 0.6681\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 4s 657ms/step - loss: 1.3363 - accuracy: 0.6611 - val_loss: 1.4720 - val_accuracy: 0.6667\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 1.3293 - accuracy: 0.6678 - val_loss: 1.4843 - val_accuracy: 0.6476\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 4s 663ms/step - loss: 1.3109 - accuracy: 0.6790 - val_loss: 1.4588 - val_accuracy: 0.6617\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 4s 659ms/step - loss: 1.3231 - accuracy: 0.6659 - val_loss: 1.4268 - val_accuracy: 0.6723\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 4s 654ms/step - loss: 1.2899 - accuracy: 0.6765 - val_loss: 1.4187 - val_accuracy: 0.6730\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 4s 660ms/step - loss: 1.2981 - accuracy: 0.6766 - val_loss: 1.4713 - val_accuracy: 0.6653\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 4s 655ms/step - loss: 1.3763 - accuracy: 0.6575 - val_loss: 2.2890 - val_accuracy: 0.3665\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 4s 667ms/step - loss: 2.1884 - accuracy: 0.3240 - val_loss: 1.7709 - val_accuracy: 0.5862\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 4s 665ms/step - loss: 1.7289 - accuracy: 0.5099 - val_loss: 1.7890 - val_accuracy: 0.4400\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 1.7072 - accuracy: 0.4643 - val_loss: 1.6508 - val_accuracy: 0.4605\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 1.5951 - accuracy: 0.5265 - val_loss: 1.5622 - val_accuracy: 0.5989\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 4s 658ms/step - loss: 1.4991 - accuracy: 0.6374 - val_loss: 1.4991 - val_accuracy: 0.6497\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 4s 649ms/step - loss: 1.4355 - accuracy: 0.6524 - val_loss: 1.4904 - val_accuracy: 0.6518\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 4s 650ms/step - loss: 1.3875 - accuracy: 0.6783 - val_loss: 1.4529 - val_accuracy: 0.6603\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 1.3766 - accuracy: 0.6705 - val_loss: 1.4368 - val_accuracy: 0.6638\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 4s 643ms/step - loss: 1.3974 - accuracy: 0.6510 - val_loss: 1.4515 - val_accuracy: 0.6561\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 4s 671ms/step - loss: 1.3898 - accuracy: 0.6513 - val_loss: 1.4584 - val_accuracy: 0.6547\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 4s 654ms/step - loss: 1.3635 - accuracy: 0.6516 - val_loss: 1.4670 - val_accuracy: 0.6645\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 4s 654ms/step - loss: 1.3477 - accuracy: 0.6683 - val_loss: 1.4300 - val_accuracy: 0.6631\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 4s 655ms/step - loss: 1.3160 - accuracy: 0.6731 - val_loss: 1.5107 - val_accuracy: 0.6504\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 4s 652ms/step - loss: 1.3119 - accuracy: 0.6834 - val_loss: 1.4228 - val_accuracy: 0.6638\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 4s 669ms/step - loss: 1.2961 - accuracy: 0.6804 - val_loss: 1.4358 - val_accuracy: 0.6653\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 4s 648ms/step - loss: 1.2936 - accuracy: 0.6830 - val_loss: 1.4588 - val_accuracy: 0.6667\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 4s 659ms/step - loss: 1.2961 - accuracy: 0.6867 - val_loss: 1.4550 - val_accuracy: 0.6363\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 1.3183 - accuracy: 0.6618 - val_loss: 1.4355 - val_accuracy: 0.6744\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 4s 660ms/step - loss: 1.3061 - accuracy: 0.6816 - val_loss: 1.8997 - val_accuracy: 0.5911\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 4s 651ms/step - loss: 1.6713 - accuracy: 0.6416 - val_loss: 1.5108 - val_accuracy: 0.6349\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 4s 654ms/step - loss: 1.4516 - accuracy: 0.6407 - val_loss: 1.4712 - val_accuracy: 0.6589\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 4s 641ms/step - loss: 1.3881 - accuracy: 0.6670 - val_loss: 1.4560 - val_accuracy: 0.6518\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 4s 662ms/step - loss: 1.3185 - accuracy: 0.6676 - val_loss: 1.4363 - val_accuracy: 0.6455\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 4s 650ms/step - loss: 1.3047 - accuracy: 0.6679 - val_loss: 1.4555 - val_accuracy: 0.6638\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 1.2743 - accuracy: 0.6744 - val_loss: 1.4731 - val_accuracy: 0.6582\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 4s 654ms/step - loss: 1.2772 - accuracy: 0.6750 - val_loss: 1.4470 - val_accuracy: 0.6638\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 4s 666ms/step - loss: 1.2537 - accuracy: 0.6883 - val_loss: 1.4551 - val_accuracy: 0.6554\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 4s 648ms/step - loss: 1.2585 - accuracy: 0.6812 - val_loss: 1.4619 - val_accuracy: 0.6561\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 4s 657ms/step - loss: 1.2671 - accuracy: 0.6886 - val_loss: 1.4346 - val_accuracy: 0.6589\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 4s 651ms/step - loss: 1.2552 - accuracy: 0.6873 - val_loss: 1.4438 - val_accuracy: 0.6504\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 4s 659ms/step - loss: 1.2287 - accuracy: 0.6842 - val_loss: 1.4424 - val_accuracy: 0.6610\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 4s 662ms/step - loss: 1.2397 - accuracy: 0.6862 - val_loss: 1.4404 - val_accuracy: 0.6596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B_BKjzda387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a9710555-7a25-48e8-afd6-5efd99d34fa3"
      },
      "source": [
        "# Plot the Model loss\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6qIeYiBjZSf"
      },
      "source": [
        "Changes from Part 3:\n",
        "- Added Early Stopping with a patience limit (how long before the training stops) of 50\n",
        "- Removed second Dense layer\n",
        "- Changed learning rate to 0.0003"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7BEuccYvit"
      },
      "source": [
        "## Part 5: Looking at the Predictions (20 points)\n",
        "---\n",
        "\n",
        "Now, Using the final (best) model you trained, show your model's performance on the test set.\n",
        "> * For COVID-19 dataset, plot the model's prediction for the number of cases and the actual daily cumulative case numbers.\n",
        "> * For Reuters dataset, calculate and display the prediction accuracy for all of the 46 different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyCzORLJELij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20abaad5-1121-4fd9-9f5b-2a9b3004302a"
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_preds_raw = model.predict(X_test)\n",
        "y_preds_raw = tf.convert_to_tensor(y_preds_raw)\n",
        "softmax = tf.keras.activations.softmax(y_preds_raw)\n",
        "y_preds = tf.math.argmax(softmax, axis=1).numpy()\n",
        "\n",
        "# print(y_preds)\n",
        "\n",
        "# print(f'Test Accuracy {np.mean(y_preds==y_test)}')\n",
        "# class_accuracies = {k:y_preds[k] for k in range(46)}\n",
        "# for i in range(46):\n",
        "#   print(f'Class {i}: {class_accuracies[i]}')\n",
        "\n",
        "cf_mat = confusion_matrix(y_test, y_preds)\n",
        "# print(cf_mat)\n",
        "# Normalize diagonal entries (accuracies of each class)\n",
        "cf_mat = cf_mat.astype('float') / cf_mat.sum(axis=1)[:, np.newaxis]\n",
        "# print(cf_mat)\n",
        "cf_mat.diagonal()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.62337662, 0.        , 0.9247606 , 0.90049751,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.50793651, 0.        , 0.        , 0.12765957,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.41666667,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}